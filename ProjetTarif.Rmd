---
title: "Projet de tarification"
author: "Mikael BOZON, Pierre MARJOLET, William LAURENT, Oskar LAVERNY"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE,}
### Options knitR par d?ffaut pour tout les chunks : 
    knitr::opts_chunk$set(echo = FALSE,warning = FALSE)

### Instalation des packages n?c?ssaires : si vous avez besoin de CASdataset d?commentez la ligne : 
     #install.packages("CASdatasets", repos = "http://dutangc.free.fr/pub/RRepos/", type="source") # ligne sp?ciale pour CASdatasets qui ne vient pas de la meme source (pas de CRAN)
    .list.of.packages <- c("dplyr", "xts", "sp", "magrittr","ggplot2","gridExtra","gtable","grid","tidyr", "purrr","broom","pscl")
    .new.packages <- .list.of.packages[!(.list.of.packages %in% installed.packages()[,"Package"])]
    if(length(.new.packages)) install.packages(.new.packages)
    lapply(.list.of.packages,function(x){library(x,character.only=TRUE)}) 
### Formating color in markdown : doit être utiliser comme ?a : `r colFmt("MY RED TEXT",'red')`
    .colFmt = function(x,color){
      outputFormat = rmarkdown::all_output_formats(knitr::current_input())#opts_knit$get("rmarkdown.pandoc.to")
      if(outputFormat == 'pdf_document')
        paste("\\textcolor{",color,"}{",x,"}",sep="")
      else if(outputFormat == 'html_document')
        paste("<font color='",color,"'>",x,"</font>",sep="")
      else
        x
      print("warnings dont matter, the point was to use the first condition")
    }

    
    
```

# TARIFICATION PAR MODELES LINEAIRES GENERALISES EN ASSURANCE NON VIE : Consignes

**Objectif** : proposer un tarif en appliquant diff?rentes m?thodes de tarification (fréquence-coût moyen ou non) vues en cours impliquant l'usage des modèles linéaires généralisés (GLM). Ce tarif pourra (ou non) être ségment? par profil pour tenir compte de l'apétence du risque.

**Logiciel utilis?** : logiciel R (logiciel libre Open Source de statistiques).

**Contexte** : ? partir d'une base sinistre d'&#39;'un portefeuille r?el d&#39;assurance non vie, plus précisément en assurance automobile (garantie Responsabilité Civile). Les bases SINISTRE et CONTRAT ? étudier sont contenues dans la librairie **CASdatasets** de R.

Les données ? elles s'intitulent **freMTPL2freq** et **freMTPL2sev**.

La signification des variables est fournie dans les fichiers d'aide de R.

Les caractéristiques sur les véhicules et les assurés ont été collect?es lors de la phase de souscription des contrats.

`r .colFmt("La façon de mener le projet (méthodes envisagées, testées, appréciation des résultats) est volontairement laissée très libre afin de responsabiliser les étudiants et leur permettre de développer un esprit critique.",'red')`



**Informations pratiques** : le projet se fait par groupe de 4 (aucun travail impliquant un nombre différent d'&#39;'étudiants ne sera noté, hormis pour un groupe si le nombre d'étudiants global n'est pas un multiple de 4). Il est à rendre pour le 14 janvier 2018 avril minuit maximum en renvoyant à l'adresse [xavier.milhaud@univ-lyon1.fr](mailto:xavier.milhaud@univ-lyon1.fr) les documents suivants:

- --un rapport qui décrit votre approche et vos résultats,
- --le script R **comment?** qui vous a servi à obtenir vos résultats.

Ce rapport ne devra pas dépasser 6 pages (sans compter la page de garde si vous en mettez une, et hors annexes éventuelles où des graphiques ou autres informations peuvent être insérés). La taille des annexes est également limitée à 5 pages.

**Les fichiers envoyés devront être nommés de la façon suivante: nom1-nom2-nom3-nom4.extension**

**`r .colFmt("Vous devez vous inspirer du travail réalisé en TP de tarification.",'red')`**

**Etapes du projet** : fusionner les bases &quot;Sinistres&quot; et &quot;Contrats&quot; de manière à faire le lien entre les montants de sinistre et les contrats qui y sont liés.



Voici les grandes étapes attendues à titre indicatif, mais vous pouvez bien sûr développer d'autres étapes personnelles:

1. 1)Proposer des statistiques descriptives sur l'ensemble des informations de la base de données: tableaux d'effectifs; indicateurs statistiques classiques; indicateurs de corrélation; densités… En déduire des messages et des actions à mener pour la modélisation à venir.

1. 2)Estimer des modèles de tarification pour expliquer la charge sinistre en fonction des facteurs de risque. Sur la base d'un raisonnement justifié et clair, optimiser le modèle de façon à retenir le modèle qui vous parait le meilleur selon un critère que vous expliciterez.

1. 3)Vous ne retiendrez à la fin qu'une unique modélisation parmi l'ensemble des types de modélisation testées. Expliquez et justifiez votre choix.

1. 4)En déduire un tarif individualisé en fonction des caractéristiques des assurés. Interpréter les résultats de manière concrète, et comparer ces résultats à votre historique.

1. 5)Apportez une vision critique de votre modélisation, et donnez des pistes d'amélioration potentielles si cela est possible.



# TARIFICATION PAR MODELES LINEAIRES GENERALISES EN ASSURANCE NON VIE : Réalisation


## Récupération des données

Les bases SINISTRE et CONTRAT à étudier sont contenues dans la librairie **CASdatasets** de R. Les données à importer s'intitulent **freMTPL2freq** et **freMTPL2sev**.

```{r Récupération des données,output=FALSE}

# On récupère les deux datasets : 
  data(freMTPL2freq)
  data(freMTPL2sev)
# # Comme le package n'est pas a jour, nous effectuons une importation locale
#   load("freMTPL2freq.rda")
#   load("freMTPL2sev.rda")

# on les renomes pour sauvegarder leurs versions originales : 
  data.freq <- freMTPL2freq
  data.sev <- freMTPL2sev

#finalement on peut les regarder : 
  head(data.freq, n = 20)
  head(data.sev, n = 20)


```


On a donc à notre disposition les variables suivantes : 


* Dans la base sinistre : 
    * IDpol : Identifiant police > ne serivra pas a l'analayse, juste a merger les deux bases.
    * ClaimNb : Nombre de sinistre déclarés sur la periode d'exposition > Reste un nombre, variable a prédire pour la partie fréquance.
    * Exposure : Durée d'exposition, en années > sera un Offset pour la partie fréquance.
    * Area : Inditifiant "Area code" > déja un factor, peut servir a faire un zonnier, mais pas obligatoire.
    * VehPower : Puissance du véhicule, ordonnée en catégories > doit être un factor, variable explicative.
    * VehAge : L'age du véhicule, en années > on peut faire des classes d'age pour récupérer un factor
    * DrivAge : L'age du conducteur (en france, on peut conduire a partir de 18ans) > Idem, des classes d'ages
    * BonusMalus : Coefficient Bonus/malus, entre 50 et 350. > On peut le garder en integer, je ne sais s'il faut el considérer comme une vairbale explicative, ou plutot l'appliquer a la fin sur la prime.
    * VehBrand : La marque du véhicule (catégories inconues) > reste un factor
    * VehGas : le type de carburant, "Diesel" ou "Regular" > devient un factor
    * Density : Nombre d'habitant par km2 dans la ville ou habite le conducteur > aucune idée, peut serivr a plusieurs choses.
    * Region : Les régions de polices, basées sur la classification standard française > clairment un facteur, sert a faire un zonnier.
* Dans la base contrat : 
    * IDpol : Identifiant police
    * ClaimAmout : Cout total du sinistre, vu a une date récente ( à l'ultime).
    
```{r "Data management : Section du jeu de données en un jeu d'apprentissage et un jeu de test & petites clarifications"}

#data.freq$ClaimNb n'est pas un vecteur de la même taille que le jeu de données. réctifions
data.freq$ClaimNb <- as.vector(data.freq$ClaimNb)

# On se fixe une porportion de notre jeux de données sur lequel nous allons entrainer nos models puis de quoi le backtester
# On note proper car ce sont nos jeux de données tout neufs :)
proportion = 0.80

#Je fais une liste d'éléments pris au hazard dans les indices de notre BDD de fréquence
index_entrainement <- seq(from = 1, to = nrow(data.freq)) %>% sample(.,size = proportion * nrow(data.freq))

proper.train.freq <- data.freq[index_entrainement,]
cat("Une proportion de",round(100* nrow(proper.train.freq) / nrow(data.freq), 2), "% a été conservé pour entrainer nos modèles\n")

proper.test.freq <- data.freq[! seq(from = 1, to = nrow(data.freq)) %in% index_entrainement, ]

```

# Partie fréquence 

```{r "Base fréquence : typage des champs et regrouppement de modalitées",include=FALSE}

################################################
######################## Mise en place de l'environnement
################################################

train.freq <- proper.train.freq

# Ainsi tout ce que j'ai fait ici est en fait a faire uniquement sur le dataset d'apprentissage. 
# De plus, j'ai séparer dans deux chunks les regrouppements de modalitées et les fitting de modèles. Pas sur qu'il fallais faire comme ça. J'ai peut d'avoir trop regroupper car mes modèles fittent très bien. Ou alors c'est juste que la BDD est enorme. 


# A propos des graphiques : 
# Plutot que de faire simplement des histogrames, en comptant 1 dans chaque observation, il faurais compter l'exposure de chaque observation... Je ne sais pas comme faire. 
# Ou plutot si, je sais


# Commençons par réduire la taille de la data pour pouvoir travailler tranquilement si besoin. (pas obligatoire)

# Re-factorisons certaines variables :

str(train.freq)
cols <- c("VehGas")
train.freq[cols] <- lapply(train.freq[cols], function(x) factor(x))
str(train.freq)

par(mfrow=c(2,2))

# Fonction qui fabrique les plots : prérequis : 
makeplot <- function(data,var,title="Before",continuous=TRUE){
  
  p <- data %>% ggplot(aes(x = data[,var],weight = Exposure,fill=as.factor(ClaimNb)), environment = environment())
  
  if(continuous){p = p + geom_histogram()}
  else          {p = p + geom_bar()}
  
  p = p + ggtitle(title) + labs(fill="Nombre de Sinitres",x=var,y="Exposition Totale")  
  return(p)
}


################################################
######################## Traitement de l'age du v?hicule
################################################
# Graphique de l'?tat du monde : 
train.freq %>% makeplot("VehAge") -> .VehAgeBefore
  
# Ok donc on peut clairement cr?er une classe 30+
#df[df$VehAge<30,] %>% 
#  qplot(data=.,VehAge,fill = as.factor(ClaimNb)) 
#et des classes plus petites de 5 ann?es chacunes entre 0 et 20, puis 20-30.

train.freq$VehAge %<>% 
  cut(., breaks = c(0, 5, 10, 15, 20, 30, max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

# Graphique de l'?tat du monde Apr?s : 
train.freq %>% makeplot("VehAge",title = "After",continuous=FALSE) -> .VehAgeAfter 

################################################
######################## Traitement de l'Age du conducteur
################################################
# Graphique de l'?tat du monde : 
train.freq %>% makeplot("DrivAge") -> .DrivAgeBefore
# Ok ce coup ci c'est moins flagrant. 
# On va faire des classes d'age classqiue 18-25 puis 25-35,35-45, etc. jusqu'a 75+ ou 85+ en fonction du nombre de pelo

#df[df$DrivAge > 75,] %>% 
#  qplot(data=.,DrivAge,fill = as.factor(ClaimNb)) # Ok donc on prend 85+, mais peut-être qu'on les rassemblera plus-tard (pour des problème de manque de donn?es.)

train.freq$DrivAge %<>% 
  cut(., breaks = c(18, seq(from = 25,to = 85,by = 10), max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

# Graphique de l'?tat du monde Apr?s : 
train.freq %>% makeplot("DrivAge",title="After",continuous=FALSE) -> .DrivAgeAfter 
################################################
######################## Traitement de la puissance du v?hicule
################################################
train.freq %>% makeplot("VehPower") -> .VehPowerBefore 

# Je propose de les regroupp?es 2 par 2 . 
table(train.freq$VehPower)
train.freq$VehPower %<>% 
  cut(., breaks = c(4,5,6,7,8,11,15), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}

train.freq %>% makeplot("VehPower",title="After",continuous=FALSE) -> .VehPowerAfter


################################################
######################## Traitement de la marque du véhicule 
################################################
# Commençons par les normaliser : 
table(train.freq$VehBrand)

train.freq$VehBrand %<>% 
  as.character %>% 
  gsub("B", "", .) %>%
  {as.numeric(.)}

table(train.freq$VehBrand)

# Puis réduisons le nombre de modalitées : Il semble en effet que les codes soit ordonnés.
train.freq %>% makeplot("VehBrand",continuous=FALSE) -> .VehBrandBefore

# APrès un premier regrouppement 2 par 2 qui ne fittais pas sur la fréquence, on tente unregrouppement en 3 classes : 
table(train.freq$VehBrand)
train.freq$VehBrand %<>% 
  cut(., breaks = c(1,3,7,11), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}


train.freq %>% makeplot("VehBrand",title="After",continuous=FALSE) -> .VehBrandAfter
# Les variables créers VariableBefore et VariableAfter contienne des graphiques, que l'on plottera plus tard. 
# Les modifications des variables ont été dirrectement appliquées à la base de données 'df', ces variables servent juste a l'affichage.

################################################
######################## Remise en route du dataset avec les regrouppements faits.
################################################

# Regardons la tete du dataset : 
str(train.freq)


```


Aprés analyse du dataset, nous avons discrétiser certains variables quatitatives via les classes de disccrétisation suivantes : 

* Pour l'age du véhicule : `r names(table(train.freq$VehAge))`
* Pour l'age du conducteur  : `r names(table(train.freq$DrivAge))`
* Pour la puissance du véhicule : `r names(table(train.freq$VehPower))`
* Pour le carburant : `r names(table(train.freq$VehGas))`

En effet, au vue des graphiques suivant donnant la densit?e de chaque Nombre de sinistre en fonction de ces variables, ces classifications nous ont parues logiques : 

```{r fig.align="center", fig.width=10}
# Affichage des différents regroupements de modalité effectués.
# lors de l'execution finale ou tout simplement pour voir ce qu'il c'est passer, décommenter les lignes suivantes : 

# grid.arrange(.VehAgeBefore, .VehAgeAfter, nrow=2, ncol=1) # clairement, toujours pas.
# grid.arrange(.DrivAgeBefore, .DrivAgeAfter, nrow=2, ncol=1) # clairement, la non plus.
# grid.arrange(.VehPowerBefore, .VehPowerAfter, nrow=2, ncol=1) # clairement, ça va pas non plus.
# grid.arrange(.VehBrandBefore, .VehBrandAfter, nrow=2, ncol=1) # clairement, ça va pas.
```


Maintenant que nos discrétisations sont faites, appliquons un relevel sur data.freq pour créer un profil de référence : On prend pour chaque variable la modalitée la plus représentée :
```{r profilDeReference}
# Le but va être de relevel automatique tout les factor du dataset sur la valeur la plus représentée : 

# petite fonction : 
Autorelevel <- function(dataset){
  
    # On commence par construire le profil de référence.
    .ProfilDeRef <- 
      dataset %>%
      Filter(is.factor,.) %>%
      map(table) %>%
      map(sort,decreasing = TRUE) %>%
      map(names) %>%
      map_chr(1)
    
    # Puis pour chaque facteur, on relever sur le profil de référence.
    for (i in names(Filter(is.factor,dataset))){
      dataset[,i] <- relevel(dataset[,i],.ProfilDeRef[i])
    }
    
    return(dataset)
}

# on applique a notre dataset : 
train.freq %<>% Autorelevel


```


Une fois ces discrétisations primaire effectuées, nous allons essayer de fitter un modèle GLM log-poisson sur la fréquence. 

Des ramifications ent erme de Zero-inflated, de Over-dispersed quasi-poisson, de Negative binomial ou de tout cela en meme temps seront ensuite possible. 
Un ajout de la version de renormalisation utilisée en TD sera aussi possible. 

Si souhaiter, on pourra aussi mettre a par la variable géographique pour la traiter en terme de zonnier. 

On va donc fitter le nombre de sinistres sur le reste des variables. 


Il faudrais aussi mettre en place un échantillon de validation et un échantillon d'apprentissagE. 
Les choix de ces échantillons peuvent être faits par bootstrap, par exemple : 
On choisis aléatoirement des échantillons, on fitte les modèles sur ces échantillons et on prend en modèle moyen. 

Une sorte de GLM bootstrapé. Why not :)

```{r Renormalisation de la fréquence}

# ici on continue d'utiliser data.freq, car on travaille surla fréquence.

# Attention, on met l'exposure en offset 
# On utilise ici une liste "mod.freq" qui contiendra tout les modèles qu'on va fabriquer sur la partie frequence.
mod.freq <- list()

# commençons par poser un modèle sur la BDD de fréquence non modifiée, brutalement avec stepAIC : 
# mod.freq$Brutal<- freMTPL2freq %>% 
#   select(-c(IDpol)) %>%
#   glm (data = ., ClaimNb ~ . , offset=log(Exposure), family=poisson(link=log)) %T>%
#   {print(summary(.))}



#names(data.freq)
# IDpol + ClaimNb + Exposure + Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region


################################################
######################## Modèles Poissoniens
################################################
# Passons a la BDD avec les regrouppements de modalité appliqué : Par déffaut on vire IDPOL

mod.freq$poissonLog<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}

mod.freq$poissonLog2<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}


#AreaF, AreaB et Density ne fittent pas bien. 
# retirons density : 
mod.freq$poissonLog3 <- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas, offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}
#Ok c'est un tout petit peu mieux. Density explique probablement AreaF, ou en tout cas elles apporte la meme information.

# mais tout le reste est plutot bon. 

################################################
######################## Modèles poissoniens surdispersés
################################################
mod.freq$odPoissonLog<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas , offset=log(Exposure), family=quasipoisson(link=log)) %T>%
  {print(summary(.))}

# le paramètre de dispertion est très proche de 1 !!! 
# C'est OUF, c'est très rare d'avoir des données qui ne sont pas overdispersé.

# on a es problèmes avecles Area, car les AreaB et AreaF sont moins représentées que les autres. 
# il faudrais peut-être regroupper.
#Bon OK meme en regrouppant ça fitte pas. Donc on les dégage.
mod.freq$odPoissonLog2<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas , offset=log(Exposure), family=quasipoisson(link=log)) %T>%
  {print(summary(.))}

mod.freq$PoissonLog4<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}


################################################
######################## Modèles ZIP
################################################

# mod.freq$ZeroInflPoissonLog<- data.freq %>% 
#   select(-c(IDpol)) %>%
#   zeroinfl(data = ., formula = ClaimNb ~ . + offset=log(Exposure), dist="poisson") %T>%
#   {print(summary(.))}
# 


#### Echec : depuis le début je traite l'exposure en offset, mais je la met dans les GLM !!! Ou peut-être pas ? 
#Testons cela : 

data = data.frame(Y = c(1,2,3,4),
               X1 = c(3,4,5,6),
               X2 = c(FALSE,FALSE,TRUE,TRUE),
               Expo = c(0.1,0.2,0.3,0.5))

glm(data=data,formula=Y ~ .,offset=log(Expo),family=poisson(link=log))


# Tout mes modèles ont pour l'instant un AIC supperieur au poisson stanard. 

# enfait on pourrais meme en rajouter pleins d'autres. A la fin on fera un classement selon un critère objectif pour retenir le meilleur. 
# on pourra essayer selon un AIC, un BIC ou autre :)

# Ok je vais faire ça. 
# Je pense que j'ai trop regroupper a priorit. Je vais essayer en supprimant un regroupement ou deux, et juste en mettant en facteur certaines variables. ou alors en faisant des regroupement moins violents, par exemple un pas e discretisation de 5 au lieu e 10 pourles ages ou qqch comme ça. 

# Comparons les résultats : 
dfMod.freq <- 
  tibble(Nom = names(mod.freq)) %>%
  mutate(
    Mod = mod.freq,
    family = map(Mod,"family"),
    glance = Mod %>% map(glance),
    tidy = Mod %>% map(tidy)
  )

# On peut par exemple prendre le modèle moyen, dans chaque famille.
dfMod.freq %>% unnest(glance)
dfMod.freq %>% unnest(tidy)

# finalement on selectionne le modèle qu'on souhaite prédire : 
mod.freq$selected <- mod.freq$PoissonLog4

```

# Partie Couts moyens 
 
```{r "Base sévérité : Préparation de notre jeux de données",include=FALSE}

#_________La première étape est de jointer les bases de données sur la IDPol

# c'est partit : 
#Joignons naivement nos données, nous garderons que celles qui présentent un claimamount (sinon elles ne servent à rien...)
#On ne retient que les polices sinistrées
#On exclue les ligne sans montant de sinistre

train.sev <- dplyr::full_join(proper.train.freq,data.sev) %>%
  subset(ClaimNb >0) %>%
  subset(ClaimAmount >0)

cat("Nombre de ligne dans notre base :", nrow(train.sev), paste0("\n", "Nombre de numero d'identifiant différent dans notre base :"), length(unique(train.sev$IDpol)), "\n")


```

```{r "On pose nos modèles de coût", output = FALSE}

#regroupement de modalité pour créer le modèle de coût

#________Voici venu le temps de s'intéresser à la mise en forme et à l'analyse des données de cette base
mod.sev <- list()

#On entraine un premier modèle random, histoire de pouvoir prédire par la suite
mod.sev$gammalog1 <- train.sev %>% 
  glm (data = ., ClaimAmount ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas, family=Gamma(link=log)) %T>%
  {print(summary(.))}

mod.sev$selected <- mod.sev$gammalog1

cat("Modèle très qualitatif\n")
cat("Modèle très nerveux\n")

```


```{r "Regroupement des modalités en vue d'un tarrif basé sur fréquence x coût"}

#
# On met en facteur les modalités de la base de test de fréquence
#


# il faudrais prévoir une fonction a la fin du fitting de fréquence qui comporte l'ensemble des regrouppements de données. 
# ainsi on aura qu'a la lancer ici sur la base de tests.
# la on duplique du code pour rien.
# meme commentaire pour le modèle de cout.


test.freq <- proper.test.freq

cols <- c("VehGas")
test.freq[cols] <- lapply(test.freq[cols], function(x) factor(x))

test.freq$VehAge %<>% 
  cut(., breaks = c(0, 5, 10, 15, 20, 30, max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

test.freq$DrivAge %<>% 
  cut(., breaks = c(18, seq(from = 25,to = 85,by = 10), max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

test.freq$VehPower %<>% 
  cut(., breaks = c(4,5,6,7,8,11,15), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}

test.freq$VehBrand %<>% 
  as.character %>% 
  gsub("B", "", .) %>% 
  {as.numeric(.)}

test.freq$VehBrand %<>% 
  cut(., breaks = c(1,3,7,11), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}

#
# On met en facteur les modalités de la base de test de cout
#

# Néant.
# On garde tout ? On va avoir un problème pour merger ça avec la test.freq.
test.sev <- dplyr::full_join(proper.test.freq,data.sev) %>%
  subset(ClaimNb >0)

```


```{r "Prédictions"}

#Seulement sur base des models selectionnés


prediction.test.freq <- predict.glm(object = mod.freq$selected, newdata = test.freq, type = "response")
length(prediction.test.freq)


prediction.test.sev <- predict.glm(object = mod.sev$selected, newdata = test.sev, type = "response")
length(prediction.test.sev)

#Construisons la table prédiction VS réalité pour la fréquence :

#Si t'es dans test.sev t'es dans test.freq? 
length(test.sev$IDpol %in% test.freq$IDpol) == length(test.sev$IDpol)

# a fignoler, voir meme afaire :P

```



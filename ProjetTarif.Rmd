---
title: "Projet de tarification"
author: "Mikael BOZON, Pierre MARJOLET, William LAURENT, Oskar LAVERNY"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE,}
### Options knitR par d?ffaut pour tout les chunks : 
    knitr::opts_chunk$set(echo = FALSE,warning = FALSE)

### Instalation des packages n?c?ssaires : si vous avez besoin de CASdataset d?commentez la ligne : 
     install.packages("CASdatasets", repos = "http://dutangc.free.fr/pub/RRepos/", type="source") # ligne sp?ciale pour CASdatasets qui ne vient pas de la meme source (pas de CRAN)
    .list.of.packages <- c("CASdatasets","dplyr", "xts", "sp", "magrittr","ggplot2","gridExtra","gtable","grid","tidyr", "purrr","broom","pscl","forcats")
    .new.packages <- .list.of.packages[!(.list.of.packages %in% installed.packages()[,"Package"])]
    if(length(.new.packages)) install.packages(.new.packages)
    lapply(.list.of.packages,function(x){library(x,character.only=TRUE)}) 
### Formating color in markdown : doit √™tre utiliser comme ?a : `r colFmt("MY RED TEXT",'red')`
    .colFmt = function(x,color){
      outputFormat = rmarkdown::all_output_formats(knitr::current_input())#opts_knit$get("rmarkdown.pandoc.to")
      if(outputFormat == 'pdf_document')
        paste("\\textcolor{",color,"}{",x,"}",sep="")
      else if(outputFormat == 'html_document')
        paste("<font color='",color,"'>",x,"</font>",sep="")
      else
        x
      print("warnings dont matter, the point was to use the first condition")
    }

library(corrplot)
    
```

# TARIFICATION PAR MODELES LINEAIRES GENERALISES EN ASSURANCE NON VIE : Consignes

**Objectif** : proposer un tarif en appliquant diff?rentes m?thodes de tarification (fr√©quence-co√ªt moyen ou non) vues en cours impliquant l'usage des mod√®les lin√©aires g√©n√©ralis√©s (GLM). Ce tarif pourra (ou non) √™tre s√©gment? par profil pour tenir compte de l'ap√©tence du risque.

**Logiciel utilis?** : logiciel R (logiciel libre Open Source de statistiques).

**Contexte** : ? partir d'une base sinistre d'&#39;'un portefeuille r?el d&#39;assurance non vie, plus pr√©cis√©ment en assurance automobile (garantie Responsabilit√© Civile). Les bases SINISTRE et CONTRAT ? √©tudier sont contenues dans la librairie **CASdatasets** de R.

Les donn√©es ? elles s'intitulent **freMTPL2freq** et **freMTPL2sev**.

La signification des variables est fournie dans les fichiers d'aide de R.

Les caract√©ristiques sur les v√©hicules et les assur√©s ont √©t√© collect?es lors de la phase de souscription des contrats.

`r .colFmt("La fa√ßon de mener le projet (m√©thodes envisag√©es, test√©es, appr√©ciation des r√©sultats) est volontairement laiss√©e tr√®s libre afin de responsabiliser les √©tudiants et leur permettre de d√©velopper un esprit critique.",'red')`



**Informations pratiques** : le projet se fait par groupe de 4 (aucun travail impliquant un nombre diff√©rent d'&#39;'√©tudiants ne sera not√©, hormis pour un groupe si le nombre d'√©tudiants global n'est pas un multiple de 4). Il est √† rendre pour le 14 janvier 2018 avril minuit maximum en renvoyant √† l'adresse [xavier.milhaud@univ-lyon1.fr](mailto:xavier.milhaud@univ-lyon1.fr) les documents suivants:

- --un rapport qui d√©crit votre approche et vos r√©sultats,
- --le script R **comment√©** qui vous a servi √† obtenir vos r√©sultats.

Ce rapport ne devra pas d√©passer 6 pages (sans compter la page de garde si vous en mettez une, et hors annexes √©ventuelles o√π des graphiques ou autres informations peuvent √™tre ins√©r√©s). La taille des annexes est √©galement limit√©e √† 5 pages.

**Les fichiers envoy√©s devront √™tre nomm√©s de la fa√ßon suivante: nom1-nom2-nom3-nom4.extension**

**`r .colFmt("Vous devez vous inspirer du travail r√©alis√© en TP de tarification.",'red')`**

**Etapes du projet** : fusionner les bases &quot;Sinistres&quot; et &quot;Contrats&quot; de mani√®re √† faire le lien entre les montants de sinistre et les contrats qui y sont li√©s.



Voici les grandes √©tapes attendues √† titre indicatif, mais vous pouvez bien s√ªr d√©velopper d'autres √©tapes personnelles:

1. 1)Proposer des statistiques descriptives sur l'ensemble des informations de la base de donn√©es: tableaux d'effectifs; indicateurs statistiques classiques; indicateurs de corr√©lation; densit√©s‚Ä¶ En d√©duire des messages et des actions √† mener pour la mod√©lisation √† venir.

1. 2)Estimer des mod√®les de tarification pour expliquer la charge sinistre en fonction des facteurs de risque. Sur la base d'un raisonnement justifi√© et clair, optimiser le mod√®le de fa√ßon √† retenir le mod√®le qui vous parait le meilleur selon un crit√®re que vous expliciterez.

1. 3)Vous ne retiendrez √† la fin qu'une unique mod√©lisation parmi l'ensemble des types de mod√©lisation test√©es. Expliquez et justifiez votre choix.

1. 4)En d√©duire un tarif individualis√© en fonction des caract√©ristiques des assur√©s. Interpr√©ter les r√©sultats de mani√®re concr√®te, et comparer ces r√©sultats √† votre historique.

1. 5)Apportez une vision critique de votre mod√©lisation, et donnez des pistes d'am√©lioration potentielles si cela est possible.



# TARIFICATION PAR MODELES LINEAIRES GENERALISES EN ASSURANCE NON VIE : R√©alisation


## R√©cup√©ration des donn√©es

Les bases SINISTRE et CONTRAT √† √©tudier sont contenues dans la librairie **CASdatasets** de R. Les donn√©es √† importer s'intitulent **freMTPL2freq** et **freMTPL2sev**.

```{r R√©cup√©ration des donn√©es,output=FALSE}

# On r√©cup√®re les deux datasets : 
  data(freMTPL2freq)
  data(freMTPL2sev)

```


On a donc √† notre disposition les variables suivantes : 


* Dans la base sinistre : 
    * IDpol : Identifiant police > ne serivra pas a l'analayse, juste a merger les deux bases.
    * ClaimNb : Nombre de sinistre d√©clar√©s sur la periode d'exposition > Reste un nombre, variable a pr√©dire pour la partie fr√©quance.
    * Exposure : Dur√©e d'exposition, en ann√©es > sera un Offset pour la partie fr√©quance.
    * Area : Inditifiant "Area code" > d√©ja un factor, peut servir a faire un zonnier, mais pas obligatoire.
    * VehPower : Puissance du v√©hicule, ordonn√©e en cat√©gories > doit √™tre un factor, variable explicative.
    * VehAge : L'age du v√©hicule, en ann√©es > on peut faire des classes d'age pour r√©cup√©rer un factor
    * DrivAge : L'age du conducteur (en france, on peut conduire a partir de 18ans) > Idem, des classes d'ages
    * BonusMalus : Coefficient Bonus/malus, entre 50 et 350. > On peut le garder en integer, je ne sais s'il faut el consid√©rer comme une vairbale explicative, ou plutot l'appliquer a la fin sur la prime.
    * VehBrand : La marque du v√©hicule (cat√©gories inconues) > reste un factor
    * VehGas : le type de carburant, "Diesel" ou "Regular" > devient un factor
    * Density : Nombre d'habitant par km2 dans la ville ou habite le conducteur > aucune id√©e, peut serivr a plusieurs choses.
    * Region : Les r√©gions de polices, bas√©es sur la classification standard fran√ßaise > clairment un facteur, sert a faire un zonnier.
* Dans la base contrat : 
    * IDpol : Identifiant police
    * ClaimAmout : Cout total du sinistre, vu a une date r√©cente ( √† l'ultime).
    
    
## Cr√©ation d'une base de test et d'une base de train


```{r "Jonction des 2 bases"}

################################################
######################## R√©cup√©ration des donn√©es et Jonction des deux bases et typage
################################################
  data.freq <- freMTPL2freq
  data.sev <- freMTPL2sev
#  data.full <- full_join(data.freq,data.sev)
  
  library(fExtremes)
  
#on identifie directement les sinstres attritionnels des sinistres graves.
  mePlot(data.sev$ClaimAmount)
#Sur le mean excess plot, on dÈtecte une rupture pour environ un montant de 200 000??? de sinistre
#Nous retenons cette valeur comme seuil de sÈparation des sinistres attritionnels des graves.
  seuil.separation <- 200000

#les sinistres graves reprÈsentent 0.07% de la base de sinistres
  nrow(data.sev[which(data.sev$ClaimAmount>seuil.separation),])/nrow(data.sev)*100

  
#petit passage intermÈdiaire pour ajouter une colonne ‡ la base qui permettra de compter le nombre de sinistres au moment de la jointure des bases de donnÈes
  data.sev.att <- data.frame(data.sev[which(data.sev$ClaimAmount<=seuil.separation),],rep(1,nrow(data.sev[which(data.sev$ClaimAmount<=seuil.separation),])))
  names(data.sev.att) <- c("IDpol","ClaimAmount","AttClaimNb")


  data.sev.grv <- data.frame(data.sev[which(data.sev$ClaimAmount>seuil.separation),],rep(1,nrow(data.sev[which(data.sev$ClaimAmount>seuil.separation),])))
  names(data.sev.grv) <- c("IDpol","ClaimAmount","GrvClaimNb")


#on agrËge les sinistres graves, uniquement dans le but d'enrichir la base de donnees generale, ce ne sera pas utilise par la suite
  sin.grv.nbcum <- aggregate(cbind(GrvClaimNb,ClaimAmount) ~ IDpol, data = data.sev.grv, sum)


#Suivant la mod√©lisation retenue (glm brutal ou d√©composition fr√©quence-co√ªt moyen), nous aurons besoins d'utiliser les sinistres cumul√©s ou la moyenne des sinistres pour chaque police
  sin.cum <- aggregate(cbind(AttClaimNb,ClaimAmount) ~ IDpol, data = data.sev.att, sum)
  names(sin.cum) <- c("IDpol","AttClaimNb", "Cum_ClaimAmount")
  sin.mean <- aggregate(ClaimAmount ~ IDpol, data = data.sev.att, mean)
  names(sin.mean) <- c("IDpol", "Mean_ClaimAmount")
  

#Il ne sous reste plus qu'√† joindre la base de frequence avec les 3 autres bases de donn√©es
  data.full <- merge(merge(merge(data.freq, sin.grv.nbcum, by="IDpol", all.x=TRUE), sin.cum, by="IDpol", all.x=TRUE), sin.mean, by="IDpol", all.x=TRUE)
  


#Les polices non sinistr√©es pr√©sentent logiquement la valeur NA comme montant moyen et cumul√© de sinistres.
#Il nous faut les remplacer par 0.
  data.full$Cum_ClaimAmount <- replace(data.full$Cum_ClaimAmount, is.na(data.full$Cum_ClaimAmount), 0)
  data.full$Mean_ClaimAmount <- replace(data.full$Mean_ClaimAmount, is.na(data.full$Mean_ClaimAmount), 0)
  data.full$AttClaimNb <- replace(data.full$AttClaimNb, is.na(data.full$AttClaimNb), 0)
  data.full$GrvClaimNb <- replace(data.full$GrvClaimNb, is.na(data.full$GrvClaimNb), 0)

#Pour autant, des polices sinistr√©es demeurent avec des montants moyens et cumul√© de sinistres attritionnel et un nombre de sinistres graves  nuls.
#Nous estimons que ce sont des erreurs dans la base de donn√©es. Dans les 2 cas, il nous faut retirer ces lignes de la base.
#Cette ligne de code permet egalement de nettoyer la base des polices dont le nombre de sinistres total est diffÈrent de la somme du nombr de sinistres attritionnels et du nombre de sinistres graves
  data.full <- data.full[-which(data.full$ClaimNb !=0 &data.full$ClaimNb != data.full$GrvClaimNb + data.full$AttClaimNb & data.full$Cum_ClaimAmount==0),]
  

#Pour que la base de donnÈes soit plus simple ‡ utiliser, nous ne conservons pas le nombre de sinistres total,  mais simplement le nombre de sinstres attritonnel
  data.full$ClaimNb <- data.full$AttClaimNb
  data.full$AttClaimNb <- NULL

################################################
######################## Typage des donn√©es
################################################

  sapply(data.full,class)
  data.full$ClaimNb <- as.numeric(data.full$ClaimNb) #le nombre de sinistres doit naturellement √™tre de type num√©rique
  data.full$IDpol <- as.factor(data.full$IDpol) #l'identifiant de la police doit √™tre une variable cat√©gorielle
  data.full$VehPower <- as.numeric(data.full$VehPower) #de m√™me pour la puissance du v√©hicule
  data.full$VehAge <- as.numeric(data.full$VehAge) #l'√¢ge est toujour num√©rique
  data.full$DrivAge <- as.numeric(data.full$DrivAge) #idem
  data.full$BonusMalus <- as.numeric(data.full$BonusMalus) #le Bonus Malus est un coefficient qui s'applique √† la prime, donc est num√©rique
  data.full$VehGas <- as.factor(data.full$VehGas) #le carburant de du v√©hicule est une variable cat√©gorielle
  data.full$Density <- as.numeric(data.full$Density) #la densit√© est de type num√©rique
  
  sapply(data.full,class)

```

```{r "Sinistres graves"}
#On peut d'abord determiner la surprime associee a ces sinitres graves qui sera ajoutee aux resultats du modele developpe pour les sinistres attritionnels
#Cette surprime correspond a la moyenne des sinistres graves sur l'ensemble des assurÈs

  surprime.sinGrv <- sum(data.sev.grv$ClaimAmount)/sum(data.full$Exposure)

```

```{r "Analyse des donn√©es"}

################################################
######################## Correction des donn√©es aberrantes
################################################

#Les donn√©es sont annuelles, il est donc anormal de rencontrer des expositions > 1
#Nous supprimons donc toutes les polices pr√©sentant une exposition > 1

data.full <- data.full[-which(data.full$Exposure > 1),]

################################################
######################## Etude de la corr√©lation des donn√©es
################################################

###____ Entre variables quantitatives

str(data.full)
cor_matrix <- cor(data.full[,c(2,3,5,6,7,8,11,13,14)], method = "pearson")

diag(cor_matrix) <- 0

corrplot(cor_matrix)

#Il est int√©ressant de remarquer que le BonusMalus est positivement corr√©l√© √† l'√¢ge du conducteur. Il ne faut pas perdre √† l'esprit que le bonus malus se calcule sur la sinistralit√© pass√©e. Il donne donc une information sur la sinistralit√© ant√©rieur du conducteur, qui est donc plus susceptible d'√™tre importante s'il est √¢g√©.
#Les variables Cum_ClaimAmount et Mean_ClaimAmount sont logiquement tr√®s corr√©l√©es

###____ Entre variables qualitatives -> test du khi2


donnees_quali <- data.full[, c(4,9,10,12)]
str(donnees_quali)

nb <- ncol(donnees_quali)-1
test_ind <- matrix(0, nrow = nb, ncol = nb)
for (i in 1:nb){
  for (j in (i+1):(nb+1)){
    test_ind[i,j-1] <- chisq.test(table(donnees_quali[,i],donnees_quali[,j]))$p.value
  }
}
colnames(test_ind) <- colnames(donnees_quali[,-1])
rownames(test_ind) <- colnames(donnees_quali[,-4])
abs(test_ind)>0.05
#elles sont toutes ind√©pendantes


###___ Analyse en composante principale

#A faire


```


```{r "Data management :creation du jeu d'apprentissage et du jeu de test & petites clarifications"}

################################################
######################## Cr√©tation d'une base de test et d'une base de train
################################################

# param√®tre : 
  set.seed(seed=100)
  .Proportion.Wanted = 0.10 # pour des question de rapidit√©e d'exection, j'ai d√©scendu la proportion a 0.01, il faut la remonter a 0.8 avent de rendre le code.

# application : 

  #data.freq$ClaimNb n'est pas un vecteur de la m√™me taille que le jeu de donn√©es. r√©ctifions
  data.full$ClaimNb <- as.vector(data.full$ClaimNb)

  #Je fais une liste d'√©l√©ments pris au hazard dans les indices de notre BDD de fr√©quence
  .index_entrainement <- (1:nrow(data.full)) %>% sample(.,size = .Proportion.Wanted * nrow(data.full))
  
  test.full <- data.full[.index_entrainement,]
  train.full <- data.full[! seq(from = 1, to = nrow(data.full)) %in% .index_entrainement, ]
  
# retour : 
  .Proportion.Achieved = round(100* nrow(train.full) / nrow(data.freq), 2)
  

# Les dataset data.freq et data.sev sont donc les originaux, non modifi√©s.
  
################################################
######################## S√©paration des bases cout-moyen et des bases fr√©quences, n√©toyage des bases.
################################################

#  .Clean <- . %>% drop_na %>% distinct

#  train.freq <- train.full %>%
#    select(-c(ClaimAmount)) %>%
#    .Clean
  
#  test.freq <- test.full %>% 
#    select(-c(ClaimAmount)) %>%
  #   .Clean
  # 
  # train.sev <- train.full %>%
  #   select(-c(ClaimNb)) %>%
  #   .Clean
  # 
  # test.sev <- test.full %>% 
  #   select(-c(ClaimNb)) %>%
  #   .Clean 

################################################
######################## Rassemblement des bases dans une seule variable Databases
################################################
  
  
  # L'id√©e : avoir tout au m√™me endroit. 
  # On mettrat aussi les mod√®les dans ce dataset, √ßa permetra de pas se faire chier pour construire les predictions a la fin.
  # 
  # 
  # .MyList = list(data.freq,data.sev,data.full,train.full,train.sev,train.full,test.freq,test.sev,test.full)
  # names(.MyList)=c("data.freq","data.sev","data.full","train.full","train.sev","train.full","test.freq","test.sev","test.full")
  # Databases <-
  #   tibble(Nom = names(.MyList)) %>%
  #   mutate(
  #     data = .MyList,
  #     Type=map_chr(Nom,function(x) unlist(strsplit(x,"[.]"))[1]),
  #     Modele=map_chr(Nom,function(x) unlist(strsplit(x,"[.]"))[2]),
  #     Nom = "Original.dataset",
  #     Selected=FALSE
  #   ) %>%
  #   select(Modele,Type,Nom,data,Selected) %>%
  #   arrange(Modele,Type) %T>%
  #   {print(.)}


```



Pr√©liminairement aux fitting de mod√®les, il est important de s√©parer la base en deux : base d'entrainement et base de test.

Tout d'abord nous jointons les deux bases par un full_join, puis nous s√©parons en base de train et base de test. Ensuite, nous cr√©ons les bases de fr√©quence et cout moeyn pour fitter nos eux mod√®les ind√©pendants : d'un cot√© les fr√©quence, pour laquelle nous droppons la colonne cout puis nous droppons toutes les lignes avec des na et les lignes en double, et de l'autre cot√© les couts pour laquelle nous droppons tout les couts avec des NA et la colonnne Nombre de sinistres, ainsi queles lignes en double.



La base etant assez volumineuse, nous choississons de conserver une proportion de `r .Proportion.Achieved` pour entrainer nos mod√®les. Ainsi, l'autre patie de la base servira a tester nos mod√®les avent, une fois valider le framework, de fitter nos mod√®les sur l'int√©gralit√© de la base. 




# Partie fr√©quence 

## Typage des champs et regrouppements pr√©liminaires




Apr√©s analyse du dataset, nous avons discr√©tiser certains variables quatitatives via les classes de disccr√©tisation suivantes : 

* Pour l'age du v√©hicule : `r names(table(train.full$VehAge))`
* Pour l'age du conducteur  : `r names(table(train.full$DrivAge))`
* Pour la puissance du v√©hicule : `r names(table(train.full$VehPower))`
* Pour le carburant : `r names(table(train.full$VehGas))`

En effet, au vue des graphiques suivant donnant la densit?e de chaque Nombre de sinistre en fonction de ces variables, ces classifications nous ont parues logiques : 

```{r fig.align="center", fig.width=10}
# Affichage des diff√©rents regroupements de modalit√© effectu√©s.
# lors de l'execution finale ou tout simplement pour voir ce qu'il c'est passer, d√©commenter les lignes suivantes : 

# grid.arrange(.VehAgeBefore, .VehAgeAfter, nrow=2, ncol=1) # clairement, toujours pas.
# grid.arrange(.DrivAgeBefore, .DrivAgeAfter, nrow=2, ncol=1) # clairement, la non plus.
# grid.arrange(.VehPowerBefore, .VehPowerAfter, nrow=2, ncol=1) # clairement, √ßa va pas non plus.
# grid.arrange(.VehBrandBefore, .VehBrandAfter, nrow=2, ncol=1) # clairement, √ßa va pas.
# grid.arrange(.AreaBefore, .AreaAfter, nrow=2, ncol=1) # clairement, √ßa va pas.
```


Maintenant que nos discr√©tisations sont faites, appliquons un relevel sur data.freq pour cr√©er un profil de r√©f√©rence : On prend pour chaque variable la modalit√©e la plus repr√©sent√©e :


Une fois ces discr√©tisations primaire effectu√©es, nous allons essayer de fitter un mod√®le GLM log-poisson sur la fr√©quence. 

Des ramifications ent erme de Zero-inflated, de Over-dispersed quasi-poisson, de Negative binomial ou de tout cela en meme temps seront ensuite possible. 
Un ajout de la version de renormalisation utilis√©e en TD sera aussi possible. 

Si souhaiter, on pourra aussi mettre a par la variable g√©ographique pour la traiter en terme de zonnier. 

On va donc fitter le nombre de sinistres sur le reste des variables. 


Il faudrais aussi mettre en place un √©chantillon de validation et un √©chantillon d'apprentissagE. 
Les choix de ces √©chantillons peuvent √™tre faits par bootstrap, par exemple : 
On choisis al√©atoirement des √©chantillons, on fitte les mod√®les sur ces √©chantillons et on prend en mod√®le moyen. 

Une sorte de GLM bootstrap√©. Why not :)

```{r "Fitting du mod√®le de fr√©quence",include=FALSE}

#on definit une base d'apprentissage et une de test pour la fr√©quence
data.freq.train <- train.full
data.freq.test <- test.full





#######_____________     Cette partie du code est √† reprendre, il faut faire suivre les regroupements de modalit√© sur la base de test



################################################
######################## Preliminaires aux regrouppements de modalit√©s
################################################

 
# De plus, j'ai s√©parer dans deux chunks les regrouppements de modalit√©es et les fitting de mod√®les. Pas sur qu'il fallais faire comme √ßa. J'ai peut d'avoir trop regroupper car mes mod√®les fittent tr√®s bien. Ou alors c'est juste que la BDD est enorme. 

# Commen√ßons par r√©duire la taille de la data pour pouvoir travailler tranquilement si besoin. (pas obligatoire)

# Re-factorisons certaines variables :
#  str(data.freq.train)
#  cols <- c("VehGas")
#  data.freq.train[cols] <- lapply(data.freq.train[cols], function(x) factor(x))
#  str(data.freq.train)

#par(mfrow=c(2,2))

# Fonction qui fabrique les plots expliquant les regrouppements de modalit√©s choisis : pr√©requis : 
makeplot <- function(data,var,title="Before",continuous=TRUE){
  
  p <- data %>% ggplot(aes(x = data[,var],weight = Exposure,fill=as.factor(ClaimNb)), environment = environment())
  
  if(continuous){p = p + geom_histogram()}
  else          {p = p + geom_bar()}
  
  p = p + ggtitle(title) + labs(fill="Nombre de Sinitres",x=var,y="Exposition Totale")  
  return(p)
}


################################################
######################## Regrouppement de l'age du v?hicule
################################################
# Graphique de l'?tat du monde : 
data.freq.train %>% makeplot("VehAge") -> .VehAgeBefore
  
# Ok donc on peut clairement cr?er une classe 30+
#df[df$VehAge<30,] %>% 
#  qplot(data=.,VehAge,fill = as.factor(ClaimNb)) 
#et des classes plus petites de 5 ann?es chacunes entre 0 et 20, puis 20-30.

data.freq.train$VehAge %<>% 
  cut(., breaks = c(0, 5, 10, 15, 20, 30, max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

# Graphique de l'?tat du monde Apr?s : 
data.freq.train %>% makeplot("VehAge",title = "After",continuous=FALSE) -> .VehAgeAfter 

################################################
######################## Regrouppement de l'Age du conducteur
################################################
# Graphique de l'?tat du monde : 
data.freq.train %>% makeplot("DrivAge") -> .DrivAgeBefore
# Ok ce coup ci c'est moins flagrant. 
# On va faire des classes d'age classqiue 18-25 puis 25-35,35-45, etc. jusqu'a 75+ ou 85+ en fonction du nombre de pelo

#df[df$DrivAge > 75,] %>% 
#  qplot(data=.,DrivAge,fill = as.factor(ClaimNb)) # Ok donc on prend 85+, mais peut-√™tre qu'on les rassemblera plus-tard (pour des probl√®me de manque de donn?es.)

data.freq.train$DrivAge %<>% 
  cut(., breaks = c(18, seq(from = 25,to = 85,by = 10), max(.)), include.lowest = TRUE) %T>%
  {print(summary(.))}

# Graphique de l'?tat du monde Apr?s : 
data.freq.train %>% makeplot("DrivAge",title="After",continuous=FALSE) -> .DrivAgeAfter 
################################################
######################## Regrouppement de la puissance du v?hicule
################################################
data.freq.train %>% makeplot("VehPower") -> .VehPowerBefore 

data.freq.train$VehPower %<>% 
  cut(., breaks = c(4,5,6,7,8,11,15), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}

data.freq.train %>% makeplot("VehPower",title="After",continuous=FALSE) -> .VehPowerAfter

################################################
######################## Regrouppement d'Area
################################################
data.freq.train %>% makeplot("Area",continuous=FALSE) -> .AreaBefore 

data.freq.train$Area %<>% 
  fct_collapse("AB" = c("A","B"),
               "EF" = c("E","F")) %T>%
  {print(summary(.))}

data.freq.train %>% makeplot("Area",title="After",continuous=FALSE) -> .AreaAfter



################################################
######################## Regrouppement de la marque du v√©hicule 
################################################
# Commen√ßons par les normaliser : 

data.freq.train$VehBrand %<>% 
  as.character %>% 
  gsub("B", "", .) %>%
  {as.numeric(.)}

table(data.freq.train$VehBrand)

# Puis r√©duisons le nombre de modalit√©es : Il semble en effet que les codes soit ordonn√©s.
data.freq.train %>% makeplot("VehBrand",continuous=FALSE) -> .VehBrandBefore

# APr√®s un premier regrouppement 2 par 2 qui ne fittais pas sur la fr√©quence, on tente unregrouppement en 3 classes : 
table(data.freq.train$VehBrand)
data.freq.train$VehBrand %<>% 
  cut(., breaks = c(1,3,7,11), include.lowest = TRUE,right=FALSE) %T>%
  {print(summary(.))}


data.freq.train %>% makeplot("VehBrand",title="After",continuous=FALSE) -> .VehBrandAfter
# Les variables cr√©ers VariableBefore et VariableAfter contienne des graphiques, que l'on plottera plus tard. 
# Les modifications des variables ont √©t√© dirrectement appliqu√©es √† la base de donn√©es 'df', ces variables servent juste a l'affichage.
  
################################################
######################## Cr√©ation du profil de r√©f√©rence
################################################
# Le but va √™tre de relevel automatique tout les factor du dataset sur la valeur la plus repr√©sent√©e : 

# petite fonction : 
Autorelevel <- function(dataset){
  
    # On commence par construire le profil de r√©f√©rence.
    .ProfilDeRef <- 
      dataset %>%
      Filter(is.factor,.) %>%
      map(table) %>%
      map(sort,decreasing = TRUE) %>%
      map(names) %>%
      map_chr(1)
    
    # Puis pour chaque facteur, on relever sur le profil de r√©f√©rence.
    for (i in names(Filter(is.factor,dataset))){
      dataset[,i] <- relevel(dataset[,i],.ProfilDeRef[i])
    }
    
    return(dataset)
}

data.freq.train %<>% Autorelevel


#Reprendre le setup de l'environnement

################################################
######################## Setup de l'environnement
################################################

# # R√©cup√©ration de la bonne base de donn√©e  de fr√©quence 
# train.freq <- 
#   Databases %>% 
#   filter(Modele=="freq",Type=="train") %>%
#   .$data %>%
#   `[[`(1)

# On utilise ici une liste "mod.freq" qui contiendra tout les mod√®les qu'on va fabriquer sur la partie frequence.
mod.freq <- list()

################################################
######################## Mod√®les Poissoniens
################################################

# Attention, on met l'exposure en offset 

#names(data.freq.train)
# IDpol + ClaimNb + Exposure + Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region

# Passons a la BDD avec les regrouppements de modalit√© appliqu√© : Par d√©ffaut on vire IDPOL

mod.freq$poissonLog<- data.freq.train %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}

# on vire dirrectement la r√©gion : 
mod.freq$poissonLog2<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}

# ou alors plutot la puissance du v√©hicule : 
mod.freq$poissonLog2b<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region  , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}

# ha c'est mieux. 
# Et si on vire les deux : 
mod.freq$poissonLog2c<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density, offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}
# c'est encore mieux.
  
# retirons density : 
mod.freq$poissonLog3 <- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehAge + DrivAge + BonusMalus + VehBrand + VehGas, offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}

# retirons la marque du v√©hicule : 
mod.freq$poissonLog4 <- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehAge + DrivAge + BonusMalus + VehGas, offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}
#Ok c'est un tout petit peu mieux. Density explique probablement AreaF, ou en tout cas elles apporte la meme information.

# mais tout le reste est plutot bon. 

################################################
######################## Mod√®les poissoniens surdispers√©s
################################################
mod.freq$odPoissonLog<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas , offset=log(Exposure), family=quasipoisson(link=log)) %T>%
  {print(summary(.))}

# le param√®tre de dispertion est tr√®s proche de 1 !!! 
# C'est OUF, c'est tr√®s rare d'avoir des donn√©es qui ne sont pas overdispers√©.

# on a es probl√®mes avecles Area, car les AreaB et AreaF sont moins repr√©sent√©es que les autres. 
# il faudrais peut-√™tre regroupper.
#Bon OK meme en regrouppant √ßa fitte pas. Donc on les d√©gage.
mod.freq$odPoissonLog2<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas , offset=log(Exposure), family=quasipoisson(link=log)) %T>%
  {print(summary(.))}

mod.freq$PoissonLog4<- train.freq %>% 
  glm (data = ., ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas , offset=log(Exposure), family=poisson(link=log)) %T>%
  {print(summary(.))}


################################################
######################## Mod√®les ZIP
################################################

# mod.freq$ZIPLog <-
#   zeroinfl(data = train.freq, formula = ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region, offset=log(Exposure), dist="poisson") %T>%
#   {print(summary(.))}

################################################
######################## Mod√®les ZIBN
################################################
# # Mod√®le complet : ( attention tr√®√®√®√®√®s long a fitter)
# mod.freq$ZIBNLog <-
#   zeroinfl(data = train.freq, 
#            formula = ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density + Region, offset=log(Exposure), dist="negbin") %T>%
#            {print(summary(.))}
# 
# 
# # On vire Area dans le mod√®le de zero-inflation et Region des deux cot√©s.
# mod.freq$ZIBNLog2 <-
#   zeroinfl(data = train.freq, 
#            formula = ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density | VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Density, 
#            offset=log(Exposure),
#            dist="negbin") %T>%
#            {print(summary(.))}
# 
# # On vire density
# mod.freq$ZIBNLog3 <-
#   zeroinfl(data = train.freq, 
#            formula = ClaimNb ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas  | VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas,
#            offset=log(Exposure), dist="negbin") %T>%
#            {print(summary(.))}

# Bon au final les zeroinfl c'est pas la joie, le poisson va tr√®s bien.

################################################
######################## Regrouppement des mod√®les fitt√©s
################################################
# ajout des mod√®les fitt√©s a la base de donn√©e : 
  
      # on commence par construire des stats sur les mod√®les 
      # Cette partie est un peu longue.
      dfMod <- 
      tibble(Nom = names(mod.freq)) %>%
      mutate(
        Mod = mod.freq,
        family = map(Mod,"family"),
        glance = Mod %>% map(glance),
        tidy = Mod %>% map(tidy),
        augment = Mod %>% map(augment),
        Modele="freq",
        Type="train"
      ) %T>% {print(.)}
    
      # on jointe les databases
      Databases %<>% full_join(dfMod)
      Databases[!grepl("Original",Databases$Nom),] %<>%
        mutate(data = Mod %>% map("data"))
      Databases %<>%
        {print(.)}

################################################
######################## Selection d'un mod√®le 
################################################

# AU vue de tout les mod√®les fitt√©s, il faudrais d√©finir un crit√®re pour en choisir un. 
# je pense qu'un bon crit√®re serais de regarder leur AIC et BIC respectifs, voir d'autres statistiques (null.deviance) ou autre.
# Si c'est le cas, on peut r√©flechir comme √ßa : 
Databases[!map_lgl(Databases$glance,is.null),] %>%
  select(-c(Modele,Type,data)) %>%
  unnest(glance) %>%
  arrange(AIC) # changer ici le crit√®re de classement pour afficher les mod√®les dans un autre ordre.

# une fois le mod√®le choisis, mettre TRUE dans sa colonne selected : 
Databases[Databases$Nom=="poissonLog",]$Selected = TRUE



```

# Partie Couts moyens 


```{r "Cr√©ation d'un mod√®le de cout moyen", output = FALSE}


################################################
######################## Setup de l'environnement
################################################
# 
# # R√©cup√©ration de la bonne base de donn√©e  de fr√©quence 
# train.sev <- 
#   Databases %>% 
#   filter(Modele=="sev",Type=="train") %>%
#   .$data %>%
#   `[[`(1) # la premi√®re entr√© de la base c'est les data brutes dans mod√®le.
# 
# # On utilise ici une liste "mod.sev" qui contiendra tout les mod√®les qu'on va fabriquer sur la partie frequence.
# mod.sev <- list()





#On entraine un premier mod√®le random, histoire de pouvoir pr√©dire par la suite
mod.sev$gammalog1 <- train.sev %>% 
  glm (data = ., ClaimAmount ~ Area + VehPower + VehAge + DrivAge + BonusMalus + VehGas, family=Gamma(link=log)) %T>%
  {print(summary(.))}

cat("Mod√®le tr√®s qualitatif\n")
cat("Mod√®le tr√®s nerveux\n")

################################################
######################## Regrouppement des mod√®les fitt√©s
################################################
# ajout des mod√®les fitt√©s a la base de donn√©e : 
      dfMod <- 
      tibble(Nom = names(mod.sev)) %>%
      mutate(
        Mod2 = mod.sev,
        Modele="sev",
        Type="train"
      ) %T>% {print(.)}
    
      # on jointe les databases
      Databases %<>% full_join(dfMod)
      Databases[which(Databases$Modele=="sev" & Databases$Nom!="Original.dataset"),] %<>%
        mutate(Mod = map(Mod2,function(x) x)) %>%
        mutate(data = Mod %>% map("data")) %>%
        mutate(family = map(Mod,"family")) %>%
        mutate(glance = Mod %>% map(function(x){if(is.null(x)){return(NULL)}else{return(glance(x))}})) %>%
        mutate(tidy = Mod %>% map(function(x){if(is.null(x)){return(NULL)}else{return(tidy(x))}})) %>%
        mutate(augment = Mod %>% map(function(x){if(is.null(x)){return(NULL)}else{return(augment(x))}}))
       Databases %<>% select(-Mod2) %T>% {print(.)}

################################################
######################## Selection d'un mod√®le 
################################################
# AU vue de tout les mod√®les fitt√©s, il faudrais d√©finir un crit√®re pour en choisir un. 
# je pense qu'un bon crit√®re serais de regarder leur AIC et BIC respectifs, voir d'autres statistiques (null.deviance) ou autre.
# Si c'est le cas, on peut r√©flechir comme √ßa : 
Databases[which(Databases$Modele=="sev" & Databases$Nom!="Original.dataset"),] %>%
  select(-c(Modele,Type,data)) %>%
  unnest(glance) %>%
  arrange(AIC) # changer ici le crit√®re de classement pour afficher les mod√®les dans un autre ordre.

# une fois le mod√®le choisis, mettre TRUE dans sa colonne selected : 
Databases[Databases$Nom=="gammalog1",]$Selected = TRUE




```


```{r "Pr√©dictions"}

#Seulement sur base des models selectionn√©s

# commen√ßons par r√©cup√©rer les mod√®les : 
selec.freq <- Databases %>% filter(Modele=="freq",Type=="train",Selected==TRUE) %>% .$Mod
selec.sev <- Databases %>% filter(Modele=="sev",Type=="train",Selected==TRUE) %>% .$Mod

# puis les data : 
test.freq <- Databases %>% filter(Nom=="Original.dataset",Type=="test",Modele=="freq") %>% .$data
test.sev <- Databases %>% filter(Nom=="Original.dataset",Type=="test",Modele=="sev") %>% .$data

prediction.test.freq <- predict.glm(object = selec.freq, newdata = test.freq, type = "response")
length(prediction.test.freq)


prediction.test.sev <- predict.glm(object = selec.sev, newdata = test.sev, type = "response")
length(prediction.test.sev)

#Construisons la table pr√©diction VS r√©alit√© pour la fr√©quence :

#Si t'es dans test.sev t'es dans test.freq? 
length(test.sev$IDpol %in% test.freq$IDpol) == length(test.sev$IDpol)

# a fignoler, voir meme afaire :P

```


